{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0254ac-e018-4f47-92d8-26b4152d9ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Huzaifa Mumtaz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b299220a-7dfe-400a-9c5b-53166261e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_DIR = 'images/train'\n",
    "Test_DIR = 'images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79931e94-b00b-4ad3-b731-d4476ed75055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataFrame(dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in os.listdir(dir):\n",
    "        for imageName in os.listdir(os.path.join(dir, label)):\n",
    "            image_paths.append(os.path.join(dir, label, imageName))\n",
    "            labels.append(label)\n",
    "        print (label, 'completed')\n",
    "    return image_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d784aaf-915c-417d-8fde-19d4058abc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = createDataFrame(Train_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afad20dd-a413-43a3-b15d-2aeb3909c0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image     label\n",
      "0            images/train\\angry\\0.jpg     angry\n",
      "1            images/train\\angry\\1.jpg     angry\n",
      "2           images/train\\angry\\10.jpg     angry\n",
      "3        images/train\\angry\\10002.jpg     angry\n",
      "4        images/train\\angry\\10016.jpg     angry\n",
      "...                               ...       ...\n",
      "28816  images/train\\surprise\\9969.jpg  surprise\n",
      "28817  images/train\\surprise\\9985.jpg  surprise\n",
      "28818  images/train\\surprise\\9990.jpg  surprise\n",
      "28819  images/train\\surprise\\9992.jpg  surprise\n",
      "28820  images/train\\surprise\\9996.jpg  surprise\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb56b34-14b1-498c-97ff-eba7cd3bdc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry completed\n",
      "disgust completed\n",
      "fear completed\n",
      "happy completed\n",
      "neutral completed\n",
      "sad completed\n",
      "surprise completed\n"
     ]
    }
   ],
   "source": [
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = createDataFrame(Test_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3677635-f943-490a-a09d-d458c90784bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image     label\n",
      "0       images/test\\angry\\10052.jpg     angry\n",
      "1       images/test\\angry\\10065.jpg     angry\n",
      "2       images/test\\angry\\10079.jpg     angry\n",
      "3       images/test\\angry\\10095.jpg     angry\n",
      "4       images/test\\angry\\10121.jpg     angry\n",
      "...                             ...       ...\n",
      "7061  images/test\\surprise\\9806.jpg  surprise\n",
      "7062  images/test\\surprise\\9830.jpg  surprise\n",
      "7063  images/test\\surprise\\9853.jpg  surprise\n",
      "7064  images/test\\surprise\\9878.jpg  surprise\n",
      "7065   images/test\\surprise\\993.jpg  surprise\n",
      "\n",
      "[7066 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "830de4e6-2977-44dc-90b1-e7f8f412922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e76a4358-2446-4142-8231-bb59e2fd54ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale = True)\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9909ec73-3f75-47c3-b3ab-f2b5164b9366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd289ffab3624c97839b7100e3c36c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huzaifa Mumtaz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_features = extract_features(train['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "427fdbac-922e-43f4-b143-78889e6e62b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed549a48713c464b9ea7c370aade22c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features = extract_features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc9126cb-91f4-4ff4-8348-b9f764002d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "497755d4-dc95-4387-9ddd-8ca81031f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ad50206-a428-4c6d-8b20-496bc94bcade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83a17e55-681a-4269-b9a3-647bb6849804",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4588e5de-d1ed-4692-b3bd-ff58cc4c510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes = 7)\n",
    "y_test = to_categorical(y_test, num_classes = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e90b066-0753-463e-8ee6-58f2413254a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Huzaifa Mumtaz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Huzaifa Mumtaz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# convolutional Layers\n",
    "model.add (Conv2D(128, kernel_size= (3,3), activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add (Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D (256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add (Dropout (0.4))\n",
    "\n",
    "model.add (Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add (Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D (512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add (Dropout(0.4))\n",
    "\n",
    "model.add (Flatten())\n",
    "#fully connected Layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add (Dropout (0.3))\n",
    "# output Layer\n",
    "model.add (Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d85a4bc-05df-4eda-a54f-6468bea22c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Huzaifa Mumtaz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65a5f53c-02eb-45ed-bb2e-c197454c840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\Huzaifa Mumtaz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Huzaifa Mumtaz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "136/226 [=================>............] - ETA: 3:38 - loss: 1.8268 - accuracy: 0.2451"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size = 128, epochs = 100, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b04977fe-140e-46d6-b5af-f300d562537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huzaifa Mumtaz\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"emotiondetector.json\", 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5deb4870-5ca3-4e23-bfb2-4257570dba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5baf7c04-1461-40c1-beb0-09759989a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(\"emotiondetector.json\", \"r\")\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"emotiondetector.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d696555f-90d3-4674-90e2-ebc91fc809e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c46adc3-b727-4c5c-9720-2807db843841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ef(image):\n",
    "    img = load_img(image, grayscale = True)\n",
    "    feature = np.array(img)\n",
    "    feature = feature.reshape(1, 48, 48, 1)\n",
    "    return feature/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf8a0d12-ca5c-48b8-98c9-054c4b3730dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image is of sad\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "model prediction is  happy\n"
     ]
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"Original Image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \", pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "288fcccf-8bfa-4acc-9dcd-5b3f2322733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e03664fc-4491-4529-9b39-636f4d3bfa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image is of sad\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "model prediction is  happy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2307ceada10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGeCAYAAADSRtWEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxFklEQVR4nO3df2xV93nH8ccGbIx/G4NtfhhQg0JSBm1IQtyypQW3KKsiGNbUaZXG2mhVMxOF8McWpDXVqk2mqZSk2UhSbYysUjMyNpEqrfJLpDjdiimY0JJfLFspmIHtUrCNbbCNffZHihcXzvOx/cX9XuD9kq6U+PH33HO/53vvw4XnOd+sJEkSAwDgtyw79gkAAG5MJCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFJNjn8BvGhoaspMnT1phYaFlZWXFPh0AwBglSWLnzp2zWbNmWXa28z0nmSB///d/n8ybNy/Jzc1N7rzzzmTfvn2jGtfS0pKYGQ8ePHjwuMYfLS0t7uf9hHwDev75523Tpk32zDPP2PLly+2JJ56w1atX25EjR2zmzJnu2MLCQjMz++Y3v2l5eXlX/J0pU6akjlffmi5evOjGh4aG3LiXzd1Mb2aJuO3epEmTUmPqdU3kt0X1ukKeW431rrUar67lwMCAG1fXy4v39/e7Y9U6HBwcHPexe3t73XjIvKg5U8/9P//zP6mxX/ziF+5Yb07MzE6fPp0aKyoqcseGXA8z/72rjl1QUODGz58/nxrr6Ohwx06e7H/EqzVeVVWVGps6dWpqbHBw0N55553hz/PU83Oj4/TYY4/Zn/3Zn9kXv/hFMzN75pln7Ac/+IH90z/9kz388MPu2EsfKHl5eSSgMRybBHS5mAnIu5ZmYR946tjqdat4yDpUH9Te9VSvS/HWgjrv0PduyOdCSHyi/2DqXZPRXC/1/Fe9CKG/v9+am5uttrb2/58kO9tqa2tt7969l/1+X1+fdXV1jXgAAK5/Vz0BnT592gYHB62iomLEzysqKqy1tfWy329oaLDi4uLhx9y5c6/2KQEAMlD0MuzNmzdbZ2fn8KOlpSX2KQEAfguu+r8BlZeX26RJk6ytrW3Ez9va2qyysvKy38/NzbXc3NyrfRoAgAx31RNQTk6OLVu2zHbv3m1r1641sw/+0XP37t22YcOGUR8nOztb/uPceEzkP9qpf6hU1D8Oe9Q/CHqvK3ROQuKqSkcd25uzkKKP0Yz3nlutXfXcIWtfrSNVKOBdk9D35MKFC1NjPT097livGkzFz5496471qr3Mws7NqxYbjbRiLDNdEXnmzBk3Pm3aNDfuvW7vi8NoPwsnpApu06ZNtn79erv99tvtzjvvtCeeeMJ6enqGq+IAAJiQBPT5z3/efvnLX9ojjzxira2t9rGPfcxefvnlywoTAAA3rgm7Fc+GDRvG9FduAIAbS/QqOADAjYkEBACIggQEAIgi47ZjuCQrKyu1BDek9FaVoKrxse43FXJfstE8d8ixlZAScCX03EKO7cXV65rIdZaTk+PG1X3ovDJseW8vcW7eveA++tGPumPffvttN15eXp4aU2XUqlxZ3czUuymoutbqepWVlaXGvBuwmunzViX73s1li4uLU2Pqc/YSvgEBAKIgAQEAoiABAQCiIAEBAKIgAQEAoiABAQCiIAEBAKLI2D6goaGh1Br1kH4ZJaRfZiJ7WlS9fsiWCBOx7cVoqdcV0lsVspWDme6X8a6XOu+Qfhp1bLXFxURu+6Geu6+vLzVWUlLijp0zZ864n9vrZzEzO3bsmBv3+pfMzAoKClJjnZ2d7li1XYN37CvtsfZh6nWpdej183i9U6NdY3wDAgBEQQICAERBAgIAREECAgBEQQICAERBAgIAREECAgBEkbF9QBcvXkztwwjp9ZnInpeJ7GlRJnLvmomMh86Zd2zVs6Liak69PiE1J7m5uW48pG9LzWnIWgnpjTIzy8vLS42pPXuqqqrcuHc91Zx0d3e7cdXLU1FRkRo7f/68O9brjTLze5jmz5/vjj169KgbV31b3lrz5my0n9F8AwIAREECAgBEQQICAERBAgIAREECAgBEQQICAERBAgIARJGxfUDZ2dmpNeheTb+3f8Vo4orXa5CTk+OOVTX3as8Rj6q79/pKQvamGc1zh+w/o65XSE+Ymm91vbznVuetepBC9pZSvTpqnXrXS833RPa6qTn19sYJ2ffGzOynP/2pG/d6dVTPl+p/OnXqVGpM9QGVlpa68Y6ODjfuvUe8OaUPCACQ0UhAAIAoSEAAgChIQACAKEhAAIAoSEAAgCgytgx70qRJqaWqXimnKrcMvVW9V5qrynZV+etElmGHlp9P1HOrOVPX0ys5DilNNwsrHw8tXfeoEm5Fzbk3p+p1qXO7cOHCuM9r6tSpbty7niUlJe7Ym266yY2r7RqOHTuWGlNl2Oq96ZVKDwwMuGNnz57txltbW924N6fe66IMGwCQ0UhAAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKDK2D6ivry+158DrF1B9CKE9FCG3IO/v73fj3usKuY292dW5dfp4jq3i6nqo3hCvV0f18aj+i5A+oNDtFrxrEjLfZnoteeND+5u83hG1jYTqp/Gul1pHBQUFbvwTn/iEG/f6aaZNm+aOVdsxeL1TR48edcfefffdbvzw4cNufLxb39AHBADIaCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFBnbBzQ0NJRag+71C6geCLWniOoN8Wry+/r63LG/+tWv3Hh+fn5qrLS01B1bVFTkxvPy8lJjqmdF1fSH9BFNZH9TaC9OSL9MyL5S6rnVGg193d4eMyF7Vpn556bmTL2u3t7e1Jh6fyiFhYVu3NtP6J133nHHqh4kby20t7e7Y733vZl+Xd7nndcjRB8QACCjkYAAAFGQgAAAUZCAAABRkIAAAFGQgAAAUWRsGbZX/hdSUuwd10yXmXq3hFelhzNmzHDjZ8+eTY29//777livdNbMbObMmamxqqoqd6wq1VSl7eo2+plKbQ/grTVVZq3iHlUers5b8bYPUCXgIdtnqLFembWZf97q/dHd3e3Gu7q63PiiRYtSY83Nze5YVSrttXeoz7N//dd/deNqKwivNcRbZ5RhAwAyGgkIABAFCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQRcb2AWVnZ6f2O/T396eOUz0nIbfYN/N7FVQfQ05OjhsvLy9Pjan+C9Uj0dHRkRpTPUbquUtKSty410tQUVEx7rGKutahW0F4fUCqnyxkHap1pnrhVJ+Qd+6qbyRkztV7T22pcObMmdSY6pdRc+r16JmZVVZWpsZmz57tjlU9Rl5PTegar66uduMnT55MjX3kIx9JjQ0ODtpbb73lHttsHN+A3njjDbv33ntt1qxZlpWVZS+88MKIeJIk9sgjj1hVVZXl5eVZbW2t/IADANx4xpyAenp6bOnSpbZ169Yrxh999FF78skn7ZlnnrF9+/ZZfn6+rV69Wv4JBABwYxnzX8Hdc889ds8991wxliSJPfHEE/ZXf/VXtmbNGjMz+853vmMVFRX2wgsv2B/90R+FnS0A4LpxVYsQjh49aq2trVZbWzv8s+LiYlu+fLnt3bv3imP6+vqsq6trxAMAcP27qgmotbXVzC7/h+WKiorh2G9qaGiw4uLi4cfcuXOv5ikBADJU9DLszZs3W2dn5/CjpaUl9ikBAH4LrmoCulSK2NbWNuLnbW1tqWWKubm5VlRUNOIBALj+XdU+oAULFlhlZaXt3r3bPvaxj5nZBzXu+/bts/vvv39Mx/Kq5rw+BtXjoOr9vR4jM3/vG9V/ofocvHp/NVb14pSVlaXGVG+H6oE4d+6cG/e+1ab91ewl6nV5f2BRf5hR+xypOffWiuqdUn1C3jpV56XiqjfEe261d406trcfkOplU9fLW4dqPyD1uaD2vPKu58c//nF37J49e9y4t4/Y+fPn3bHq83DhwoVu3OsD8nqIBgYGRtUHNOYE1N3dbf/93/89/P9Hjx61Q4cOWVlZmVVXV9vGjRvtb/7mb2zhwoW2YMEC++pXv2qzZs2ytWvXjvWpAADXsTEnoAMHDtinP/3p4f/ftGmTmZmtX7/enn32WfuLv/gL6+npsS9/+cvW0dFhK1assJdffln+CQIAcGMZcwL61Kc+Jf+q6Otf/7p9/etfDzoxAMD1LXoVHADgxkQCAgBEQQICAESRsdsx5Ofnp5Z8emXD3d3d7nHVdg0FBQVu3Cu99UpMzXQpp1c+6/27m5kux/TKY9Wx1ZyocueZM2emxlQJtyqLP336dGpMzUlfX58bD9naQ13rkHJ/VTIcUmZtFtYOoMrPvbiab/X+qqqqSo2pNa5ulqzKuA8cOJAaO3XqlDt23rx5btzbSkWdl3rvqu1QvLj3/lLl35fwDQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEMU12Qfk1fSr/gtV7+/dftzMbNq0aakxtXWA2m7c699QvRtqKwjv2KG371f9GV6vQnFx8bjHmvl9Jar3Q/UBhWx7oPog1HYMXlxdDxUP2TYkdE5DtlLp7Ox0497rbm9vd8ceO3Ys6Lm9vq7PfOYz7lj1ul999dXUmPpcKC8vd+NqLXifp95WKqof7BK+AQEAoiABAQCiIAEBAKIgAQEAoiABAQCiIAEBAKIgAQEAosjYPqApU6ak9kKUlpamjlP15yH75pj5/QKql+AjH/mIG/dq8lWvjTpvb6+VnJwcd6zq/VC851b7N6k+II86b7Unj5LWp2am+ytCenEUtVZU3Ot1U/s3qevp9dOo66F6cbweP9X/5+1ZZWa2ePFiNz579uzUmOr5Kisrc+Pe9fjRj37kjv3DP/xDN/7v//7vbvwXv/hFamzdunWpsf7+fnv33XfdY5vxDQgAEAkJCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEEVG9wGl9ad4vT6q5l71QChezb6qe//xj3/sxj/xiU+kxvLz892xqm/E67FQvVNeH4+Z3pPEO77qhzlz5owb96g5U31CqmfMGx/a5+Ot09AeI8V77lOnTrlj1X5a3uv2+l3M9H5b3vVWvW7qeqjPFa9fTfVGzZgxw43fe++9qbEVK1a4Y3/+85+7cfW6n3jiidTYH//xH6fGurq67Pnnn3ePbcY3IABAJCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQZW4Y9NDSUWg46derU1HEht7EfDe+5Kyoq3LHerc3NzF599dXUmNrKobq62o17t4svKipyx6qtHlRpe2tra2rs5ZdfdseqUmmvdF2Vh6utHtTr9krb1bHVuXlzGrrGVUmyt63IwYMH3bHq3AoLC924R10Pr2y+r6/PHavOS12v9vb21Jj33jPTa8UrT1el6+p6fOMb33Dj3jYU3ntztFud8A0IABAFCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABBFxvYBZWdny7r/K1G3ole36Fe3Xb9w4UJqTN12XdXs9/b2psZeeukld2xpaakb93qUqqqq3LHFxcVuXPUBebeE9/qqzMzKy8vduNfncPHiRXesdy1Hw+sN6enpcceqdeatY9XHo6jn9rYNOXLkiDtW9dN4/Wyqj069d/Py8lJjas7UWvmv//ovNz5//vzUmHrfq+uhzs2zevVqN656AL33tte/RB8QACCjkYAAAFGQgAAAUZCAAABRkIAAAFGQgAAAUZCAAABRZGwf0MDAQGotuVc3H7pXSkFBgRv3+lbUniFnzpxx495+JvPmzXPHqp4Wr0fp1KlT7tjTp0+7cbXXyqxZs1Jjah+j6dOnu3GP2ktI9ZmpfVq81+31pIzmub21pPpCVN+J6le7+eabx/3cao3v378/NabW4dy5c914ZWVlakythf/8z/9047/7u7/rxtWePx7VB+StlZkzZ7pjJ3J/NO+zkD4gAEBGIwEBAKIgAQEAoiABAQCiIAEBAKIgAQEAosjYMuwkSVJLJwcHB1PHqVJodVt2VbaYm5ubGlNloqrc8sSJE6mxtrY2d6wqrfVKilVJsNpuoaSkxI175ZqqzFrNmVdeO57tPD5MvW5vHap1pLYN8V63WuNqzhRv2wO1JYJ63V55+vvvv++OPXr0qBv31llnZ6c7dunSpW58wYIFbtwryVdr3PtMMfNL39VaUHHFW6fe+0O9dy7hGxAAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIIqM7QPyeD0t6rbrqkcipMdC3YJf9Uh4/QLq9uY9PT1u3JszdV5quwXVG+L1y4T2rHh9Ct72Fmb6dau1pObFo/qAvN4Q1cumejDUeG8d3nLLLe7Y//3f/3XjXr+at07M9HvAm9MZM2a4Y3/nd37HjZeVlbnxkH4br3/JzF/H6lqG9gF5vD670fbgjekbUENDg91xxx1WWFhoM2fOtLVr19qRI0dG/M6FCxesvr7epk+fbgUFBVZXVyebKAEAN54xJaDGxkarr6+3pqYme+2112xgYMA++9nPjvjT90MPPWQvvvii7dy50xobG+3kyZO2bt26q37iAIBr25i+n7388ssj/v/ZZ5+1mTNnWnNzs/3e7/2edXZ22rZt2+y5556zlStXmpnZ9u3b7ZZbbrGmpia76667rt6ZAwCuaUFFCJfur3Tp70ebm5ttYGDAamtrh39n0aJFVl1dbXv37r3iMfr6+qyrq2vEAwBw/Rt3AhoaGrKNGzfaJz/5SVu8eLGZmbW2tlpOTs5lN6esqKiw1tbWKx6noaHBiouLhx/qhp4AgOvDuBNQfX29vfXWW7Zjx46gE9i8ebN1dnYOP1paWoKOBwC4NoyrRm/Dhg32/e9/39544w2bM2fO8M8rKyutv7/fOjo6RnwLamtrs8rKyiseKzc3V96OHABw/RlTAkqSxB544AHbtWuX7dmz57I9MpYtW2ZTpkyx3bt3W11dnZmZHTlyxI4fP241NTVjOrHe3t7UPozi4uLUcaouXvVfqF6EkNp31Sfk1eyrXoGQHiT1mhVvvxIz3U8TMtbreVF9OmoteL1TZmbTpk1Ljan+ppD9gNS1Vn1Aal4KCwtTY6p3qry83I2fO3cuNaZ6cRTvPaLem7NmzXLjIe9d9Qdstc683qmKigp3rPo3dTXe4703R/ueH1MCqq+vt+eee86+973vWWFh4fC/6xQXF1teXp4VFxfbfffdZ5s2bbKysjIrKiqyBx54wGpqaqiAAwCMMKYE9PTTT5uZ2ac+9akRP9++fbv96Z/+qZmZPf7445adnW11dXXW19dnq1evtqeeeuqqnCwA4Pox5r+CU6ZOnWpbt261rVu3jvukAADXP25GCgCIggQEAIiCBAQAiIIEBACIImP3A5o0aVJqr4TXd6L2gFF9QiruFWKo/gvVD+D1Kly4cCHo2N68qB4H1ecTMmche+qY+T0Uai8U9boV73qF7jvlXW/Vu6Gul1pLntLSUjeu9uwpKChIjanz9vquzPx9qVT/knrvquvlxVXPV29vrxv31mno/mchfXbe+lfzPXyMUf0WAABXGQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEEXGlmG3tram3l7du3W6KpdUpZ7qtu1eXG1roEoevbgq5VSv2ythVeetjq3Ge6XW6tiqPDakxFtda6+s18xfS6G34PeeW5U6q/JyrxTazL+FvyqvVaXSHtVCod4D3ryo7UzU9VLlzB61xtU69Urf1Zyo66XGq/dIKL4BAQCiIAEBAKIgAQEAoiABAQCiIAEBAKIgAQEAoiABAQCiyNg+oO7u7tReCa/eX/VAqJr7kD4itS2B6kEKoXqMVK9OCNUr4PWGqOvR3d3txr05Db0Fv+qR8Mar+VbHDukJU2tB9ep4PUqhvVXeuaux6nV5vT7qNau1oKjPDY/qf/L6HhXVvzTRfT4K34AAAFGQgAAAUZCAAABRkIAAAFGQgAAAUZCAAABRkIAAAFFkbB/Q8uXLU2v3X3/99dRxK1ascI+renEuXLjgxr19Wnp7e92xak8Sr0dC9bSouCe0F0D1Z3g9FmpsaC9PyLGVkD1iQnpeVB+QoubM62lR+xipOfX6o9R8qvMO2atL9fGEvEfU54LqHwxdp57QtRSKb0AAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIAoMrYM++Mf/7gVFhZeMfaTn/wkddyxY8fc486bN8+NqzJT79bpqsxaHdsrvVVloCrulXKG3op+Isuw1bmFbDOhnluV7Htlw6Gl7d7rUmW5qrRWrUOvJFmVK8csi/eeW12P0BJwb17a29vdsWoLGe/Yas5Ct2nx1pJ37NGuA74BAQCiIAEBAKIgAQEAoiABAQCiIAEBAKIgAQEAoiABAQCiyNg+oJycnNTblP/+7/9+6rjvfve77nFLS0vduLfdgpnfG6L6K1R/RkjviBrrPXdoz4rqlwnZWqC/v9+Ne3OuehFCr0dIv4zinbvq3cjNzXXj6nV7W5KosarvZKLGqvHqvEO3/fDGnz171h2rPnO8Y4f0/4Xynnu0nyl8AwIAREECAgBEQQICAERBAgIAREECAgBEQQICAERBAgIARJGxfUC9vb2ptfuLFy9OHXfrrbe6x33vvffc+O233+7GvZ4X1Z9RUFDgxkP2tlFC+oBCz8vrRejt7XXHtrW1uXHveqjXpfZvSutDu8R7XaoPSMW9c1e9UWp/GTUvXh+Q2jdH9Z2EXK+Qvi01Z+q81Vo4ffp0akxda7UOvXML3RtqIvuERoNvQACAKEhAAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKDK2DygrKyu1Rt3rU/jMZz7jHvc73/mOG/fq+c3Mpk+fnhpTfQyqF8HrF1D1+movFbWfiUft96Pi3p49nZ2d7tju7m437vVQqDlT+zeF7Cekej9UP4137JD5Ho2enp7U2LRp09yxE7k/Tch+QX19fW5c7aGknDhxIjVWWVnpjlV9WyFzpsaGfK54sdF+3vANCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEEXGlmF7vHLm0tJSd+yKFSvceFNTkxsvLi5Ojalbtqvy2JAybMXbUiF0uwU13iuBPXPmTNCxvTJsdT1UWXxIObMqGZ7I2+Cr16VKjr3XrcqZ1dYCXpm2mm+1tYBHlQWr66G2BfGOr0ruQ9ZKSHuFOvZo4mlUOf7w743loE8//bQtWbLEioqKrKioyGpqauyll14ajl+4cMHq6+tt+vTpVlBQYHV1dfLCAQBuTGNKQHPmzLEtW7ZYc3OzHThwwFauXGlr1qyxt99+28zMHnroIXvxxRdt586d1tjYaCdPnrR169ZNyIkDAK5tY/oruHvvvXfE///t3/6tPf3009bU1GRz5syxbdu22XPPPWcrV640M7Pt27fbLbfcYk1NTXbXXXddvbMGAFzzxl2EMDg4aDt27LCenh6rqamx5uZmGxgYsNra2uHfWbRokVVXV9vevXtTj9PX12ddXV0jHgCA69+YE9Dhw4etoKDAcnNz7Stf+Yrt2rXLbr31VmttbbWcnBwrKSkZ8fsVFRXW2tqaeryGhgYrLi4efsydO3fMLwIAcO0ZcwK6+eab7dChQ7Zv3z67//77bf369fbOO++M+wQ2b95snZ2dw4+WlpZxHwsAcO0Ycxl2Tk6O3XTTTWZmtmzZMtu/f79961vfss9//vPW399vHR0dI74FtbW1uXeDzc3NDb4TLQDg2hPcBzQ0NGR9fX22bNkymzJliu3evdvq6urMzOzIkSN2/Phxq6mpGfNxBwYGUvsCvF4Db6sGM7Pq6mo3fqmiL43XtzJjxgx3rKr3926zr3oJVD+A10+javZVXG0P4F0T1Veintvr9SksLHTHqr6T3t5eN+6tw5Drocar3gx17NH2aFyJmjPVe+Wdu+pfys/Pd+Mhc6bW8LFjx9x4VVWVGw/h9QeGfKaYhW05cjWMKQFt3rzZ7rnnHquurrZz587Zc889Z3v27LFXXnnFiouL7b777rNNmzZZWVmZFRUV2QMPPGA1NTVUwAEALjOmBNTe3m5/8id/YqdOnbLi4mJbsmSJvfLKK8ObwD3++OOWnZ1tdXV11tfXZ6tXr7annnpqQk4cAHBtG1MC2rZtmxufOnWqbd261bZu3Rp0UgCA6x83IwUAREECAgBEQQICAERBAgIARJGx+wENDQ2l9jN4vQiqX0b1KSxcuNCNHz58ODU2kX1Aqv9C9Tl4r1v1AqheAvW6vD6g0D4Dr9fH658YTVzNqfe6Va+NOrbXH6XWcGjfVkifnepB8uZcrYWQfauKiorc+MGDB4Oee9q0aamxvLw8d6y6niH9Teq9rd67Xvxq7GnFNyAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEAUGV2GnVZCqEoLPeqW72pH1qNHj4772F55q5lf8hh6e/+Y2zF4z632glKv68SJE6kxVf6qyrC90lozf15USXF3d7cb/82dhT9MbWGhSmsVr5VBXeuQbUNCt5nwypm9XZnN9DYsy5Ytc+Oe0PeXJ7TMOqSU2jv2aNcg34AAAFGQgAAAUZCAAABRkIAAAFGQgAAAUZCAAABRkIAAAFFkbB/Q4ODguG6/rvoUVM29um37rFmzUmMtLS3u2NmzZ7txr3Y+5Db3iuoFUHOq4l5PjOq1Ua/r9OnTqbGzZ8+6Y9WclpeXu3Hv3FQPUkFBgRv3rok6dnFxsRvv7e11497xVX9TaF9KCK/PrrGx0R07b948N15VVeXGvbWg1rD6TAr5XAjlrcOrcS35BgQAiIIEBACIggQEAIiCBAQAiIIEBACIggQEAIiCBAQAiCJj+4CSJEmtM4+5t011dXVq7P3333fHqpp9r65e7SWkeg0GBgZSY+o1qz6hkH4ANVZdL69Xp6enxx2rXldhYaEb93pe8vPz3bFq3xyvV0f14qg+IfW6Q3pa1Ll5exmpPZLUe+CnP/1pakythdtuu82Nq341b1+rkB49s7B9wkLfuyH7N40G34AAAFGQgAAAUZCAAABRkIAAAFGQgAAAUZCAAABRZGwZdlZWVmqZn1c2rEo1VdmhKpUuKSlJjU2fPt0dq0pBvbLf8+fPu2NDtmtQZaIhpZpmZjk5OakxVY7c1dXlxr0ybbUWvPMy80trzfySY1XCrUqlvXWm5ix0jXuvW11rr9zfzD83dT06OjrceFNTU2psxYoV7lh1rRVvHarrFVIqrcaqNoaQ1pDQ8nIzvgEBACIhAQEAoiABAQCiIAEBAKIgAQEAoiABAQCiIAEBAKLI2D4gj9d/obYWCO158erq58yZ445977333HhRUVFqTNXrq/4L77zV2P7+fjeuzs3rVVBjVb+Md73VWNUnpHpDvNel1lHIsUO3HFG9IyG34FfvL+96qx6jH/zgB2785ptvTo2F9mWpeEifnbpeIdudqO0xFO+aeOc12nPmGxAAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIIqM7QMaGhpKrUH3attVX4nq/VC9CN7xy8vL3bGqh8Lb80f1ISh9fX2pMTVnqk9B9Tn09vamxtScqL1U1Ll71FoI6UHy5ttMz6lHrVFF9cp5c67mW/WMee/dV1991R2r9guqqqpKjalrrfpl1JwXFBSM+9gh+wGF9C2ahb1uby2M9n3JNyAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQZ2wc0ODiYWkvu1aarvhFVc6/6Bbq6ulJjas8RFT937ty4ntdM9+KUlZWlxlR/haL2tlHn5lF9Jd71CukbMdM9FqdPn06NqXWo+i+8HiS1f5Pq8wnZD0j1N6k5b2pqSo21tLS4Y++++243Pm3atNRYfn6+O1add0j/YOiePCHUc6v4eHuQ2A8IAJDRSEAAgChIQACAKEhAAIAoSEAAgChIQACAKDK2DPvixYup5aTerb5V+auixnvlmKo8dsaMGW782LFj4z728ePH3fjhw4dTY6Wlpe5YVUYdUnKsymOLi4vduHduqoT7l7/8pRufM2eOG/fKuNVzq9vke2WsqiRYlWGrrQVOnDiRGvO2HTAze+utt9z466+/nhr79Kc/7Y4tKSlx414ptZqzkO0x1Hh1PVQbg7cWVEm9eu+qzxXvdXV3d6fGenp63OMOH39Uv5Viy5YtlpWVZRs3bhz+2YULF6y+vt6mT59uBQUFVldXZ21tbSFPAwC4Do07Ae3fv9++/e1v25IlS0b8/KGHHrIXX3zRdu7caY2NjXby5Elbt25d8IkCAK4v40pA3d3d9oUvfMH+4R/+YcRf33R2dtq2bdvsscces5UrV9qyZcts+/bt9uMf/9jtgAYA3HjGlYDq6+vtc5/7nNXW1o74eXNzsw0MDIz4+aJFi6y6utr27t17xWP19fVZV1fXiAcA4Po35iKEHTt22MGDB23//v2XxVpbWy0nJ+eyfyysqKiw1tbWKx6voaHB/vqv/3qspwEAuMaN6RtQS0uLPfjgg/bd735XVpWM1ubNm62zs3P4oW5ICAC4PowpATU3N1t7e7vddtttNnnyZJs8ebI1Njbak08+aZMnT7aKigrr7++3jo6OEePa2tqssrLyisfMzc21oqKiEQ8AwPVvTH8Ft2rVqsv6Sb74xS/aokWL7C//8i9t7ty5NmXKFNu9e7fV1dWZmdmRI0fs+PHjVlNTM7YT+3WCuxKvLl7V3Kt6f9XT4vVBqFvVq54Wr3dk+vTp7tiKigo33t7enhrz+j7UeZnpXoPf/APJh3lbUJiZnT9/3o1786LmRF3r6upqN572hyqzD9oRPGqteK9b9Y2Ul5e7ca+PTh3/4MGD7th//ud/duNr165NjXlbhpjp6+XFQ7fHUP023ueKGqt6cbzrFboVinpvd3Z2psa8LUPUeV0ypgRUWFhoixcvHvGz/Px8mz59+vDP77vvPtu0aZOVlZVZUVGRPfDAA1ZTU2N33XXXWJ4KAHCdu+p3Qnj88cctOzvb6urqrK+vz1avXm1PPfXU1X4aAMA1LjgB7dmzZ8T/T5061bZu3Wpbt24NPTQA4DrGzUgBAFGQgAAAUZCAAABRkIAAAFFk7H5A586dS923xOunUfXnqg9I9Uh4Nf2ql2DmzJlu3KurV70Cqs/B27tG7bOiequ8fVjM/HlRxz5z5sy4417vk5nZr371Kzf+85//3I17fUKqpyVkbxu1xtVamD17tht/++23U2Pf+MY33LFr1qxx4/Pnz0+NTZs2zR2rXpc3Xq1R9bmg4t4eS6GfOd549bmg+nxUn53XR+TNqZrvS/gGBACIggQEAIiCBAQAiIIEBACIggQEAIiCBAQAiCJjy7CTJEnddsErPVQljSFl1mZ+KagaW1pa6sa90kXvtuhmutTTK91VZb2q1PP06dNu3Ds3VY68cOFCN+6VO3vbdpjpElRVIu5dT3UbfHVu3nYOaqzaU0uVp3s7FN9xxx3uWHXX+/z8/NSYmjO1Tr02BvX+UNR727sm6nqFUK0fqgxb8Vpe1PtjNPgGBACIggQEAIiCBAQAiIIEBACIggQEAIiCBAQAiIIEBACIImP7gC5evJhaZ+71SEydOtU9rqqbV70IHlXvr449Y8aM1NixY8fcsarHyDu3vr4+d6zqgVD9Gb29vamxs2fPumPVnHm9COq81S3jvVvsm32wZUgatc5UD4X33KrPR/U3Pfroo268sLAwNVZbW+uOVf023vvT6+Mx09s1eGtFvTfV9VJxtdZCeGtFve/VOlPn7fUAerHR9h/xDQgAEAUJCAAQBQkIABAFCQgAEAUJCAAQBQkIABAFCQgAEEXG9gFNmjQptfbeq20P7WlRfSdeP4A6topXV1enxpqamtyxqt7f679QPQ6qX0b1AXmvW/VnqD4h73p7e8+Y+f1JZnrvKG+tqLGqf8PreVG9Ntu2bXPj7777rhv/0pe+lBpTa0H1KHn7aalje2PN/HWm3nuhfT6qZyzk2N68qPe9el1qnfb09KTGvHWo9hAbPsaofgsAgKuMBAQAiIIEBACIggQEAIiCBAQAiIIEBACIggQEAIgiY/uAKisrraCg4Ioxr39D1dR7ewmZ6V4Dr/Zd9RCpnhevb0X1V6g+BG+PGNXHE9onFLLHkuon8PqAvP16zPR5qX4bL676fNSce31bP/rRj9yxr7zyihtftWqVGy8rK0uNlZSUuGPVnHlzrt57ah16QvfrUf0y3rmF7kHmrRXVy6bem+rzcLyva7TXim9AAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKDK2DHvKlCmpJYReaaEq5ezs7HTj/f39btwrC/ZKZ810Kag33rs9/2jk5eWN63lHQ5WRetdLlY+rcuXi4mI37lG3sldzHlKSr9bpmTNnUmM7duxwx370ox914/Pnz3fjhYWFqTFVXqtel7cOVclwSBm2ErKdgpn/HvJecyi1zlT5uIp7a8FrK1HX8hK+AQEAoiABAQCiIAEBAKIgAQEAoiABAQCiIAEBAKLIuDLsS6V93d3d4xqvykDVcdUdq71SanXnZlWG7cXVXWtVGak3L6ElqCF3AVfPreIhpbmqDFvxyrBDy5W9uxyr0ln1urw7iJv5d05Xd19Wa3wi74zuCb3TtrrLtzfnIeetqGOrzzO1FrzX7R370p3o5edpon7jt+zEiRM2d+7c2KcBAAjU0tJic+bMSY1nXAIaGhqykydPWmFhoWVlZVlXV5fNnTvXWlpa5J44+ABzNnbM2dgxZ2N3o8xZkiR27tw5mzVrlt+w/Vs8p1HJzs6+YsYsKiq6ri/YRGDOxo45GzvmbOxuhDkbzV1KKEIAAERBAgIARJHxCSg3N9e+9rWvyZtS4v8xZ2PHnI0dczZ2zNlIGVeEAAC4MWT8NyAAwPWJBAQAiIIEBACIggQEAIiCBAQAiCLjE9DWrVtt/vz5NnXqVFu+fLn95Cc/iX1KGeONN96we++912bNmmVZWVn2wgsvjIgnSWKPPPKIVVVVWV5entXW1tr7778f52QzQENDg91xxx1WWFhoM2fOtLVr19qRI0dG/M6FCxesvr7epk+fbgUFBVZXV2dtbW2RzjgzPP3007ZkyZLh7v2amhp76aWXhuPMmW/Lli2WlZVlGzduHP4Zc/aBjE5Azz//vG3atMm+9rWv2cGDB23p0qW2evVqa29vj31qGaGnp8eWLl1qW7duvWL80UcftSeffNKeeeYZ27dvn+Xn59vq1avlnbWvV42NjVZfX29NTU322muv2cDAgH32s5+1np6e4d956KGH7MUXX7SdO3daY2OjnTx50tatWxfxrOObM2eObdmyxZqbm+3AgQO2cuVKW7Nmjb399ttmxpx59u/fb9/+9rdtyZIlI37OnP1aksHuvPPOpL6+fvj/BwcHk1mzZiUNDQ0RzyozmVmya9eu4f8fGhpKKisrk29+85vDP+vo6Ehyc3OTf/mXf4lwhpmnvb09MbOksbExSZIP5mfKlCnJzp07h3/n3XffTcws2bt3b6zTzEilpaXJP/7jPzJnjnPnziULFy5MXnvtteTuu+9OHnzwwSRJWGcflrHfgPr7+625udlqa2uHf5adnW21tbW2d+/eiGd2bTh69Ki1traOmL/i4mJbvnw58/drnZ2dZmZWVlZmZmbNzc02MDAwYs4WLVpk1dXVzNmvDQ4O2o4dO6ynp8dqamqYM0d9fb197nOfGzE3ZqyzD8u4u2Ffcvr0aRscHLSKiooRP6+oqLD33nsv0lldO1pbW83Mrjh/l2I3sqGhIdu4caN98pOftMWLF5vZB3OWk5NjJSUlI36XOTM7fPiw1dTU2IULF6ygoMB27dplt956qx06dIg5u4IdO3bYwYMHbf/+/ZfFWGf/L2MTEDCR6uvr7a233rL/+I//iH0q14Sbb77ZDh06ZJ2dnfZv//Zvtn79emtsbIx9WhmppaXFHnzwQXvttdds6tSpsU8no2XsX8GVl5fbpEmTLqsMaWtrs8rKykhnde24NEfM3+U2bNhg3//+9+2HP/zhiL2nKisrrb+/3zo6Okb8PnNmlpOTYzfddJMtW7bMGhoabOnSpfatb32LObuC5uZma29vt9tuu80mT55skydPtsbGRnvyySdt8uTJVlFRwZz9WsYmoJycHFu2bJnt3r17+GdDQ0O2e/duq6mpiXhm14YFCxZYZWXliPnr6uqyffv23bDzlySJbdiwwXbt2mWvv/66LViwYER82bJlNmXKlBFzduTIETt+/PgNO2dphoaGrK+vjzm7glWrVtnhw4ft0KFDw4/bb7/dvvCFLwz/N3P2a7GrIDw7duxIcnNzk2effTZ55513ki9/+ctJSUlJ0traGvvUMsK5c+eSN998M3nzzTcTM0see+yx5M0330yOHTuWJEmSbNmyJSkpKUm+973vJT/72c+SNWvWJAsWLEjOnz8f+czjuP/++5Pi4uJkz549yalTp4Yfvb29w7/zla98Jamurk5ef/315MCBA0lNTU1SU1MT8azje/jhh5PGxsbk6NGjyc9+9rPk4YcfTrKyspJXX301SRLmbDQ+XAWXJMzZJRmdgJIkSf7u7/4uqa6uTnJycpI777wzaWpqin1KGeOHP/xhYmaXPdavX58kyQel2F/96leTioqKJDc3N1m1alVy5MiRuCcd0ZXmysyS7du3D//O+fPnkz//8z9PSktLk2nTpiV/8Ad/kJw6dSreSWeAL33pS8m8efOSnJycZMaMGcmqVauGk0+SMGej8ZsJiDn7APsBAQCiyNh/AwIAXN9IQACAKEhAAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKEhAAIAoSEAAgChIQACAKP4PtMOTGTS0jKgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = 'images/train/sad/42.jpg'\n",
    "print(\"Original Image is of sad\")\n",
    "img = ef(image)\n",
    "pred = model.predict(img)\n",
    "pred_label = label[pred.argmax()]\n",
    "print(\"model prediction is \", pred_label)\n",
    "plt.imshow(img.reshape(48, 48), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8868f2-4f6c-476e-a901-c040c053bd30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbd90e-0b74-46e7-8df7-ac774a7f72ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
